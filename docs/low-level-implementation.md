# Low-Level Implementation Guide

This document provides detailed information about the internal implementation of go-crablet, including database schema, SQL functions, and low-level architectural decisions.

## Table of Contents

1. [Database Schema](#database-schema)
2. [SQL Functions](#sql-functions)
3. [Advisory Locks Implementation](#advisory-locks-implementation)
4. [Transaction Management](#transaction-management)
5. [Error Handling](#error-handling)
6. [Performance Considerations](#performance-considerations)

## Database Schema

### Events Table

The primary table that stores all events in the system:

```sql
CREATE TABLE events (
    type VARCHAR(64) NOT NULL,
    tags TEXT[] NOT NULL,
    data JSON NOT NULL,
    transaction_id xid8 NOT NULL,
    position BIGSERIAL NOT NULL PRIMARY KEY,
    occurred_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT chk_event_type_length CHECK (LENGTH(type) <= 64)
);

-- Indexes for performance
CREATE INDEX idx_events_transaction_position_btree ON events(transaction_id, position);
CREATE INDEX idx_events_tags ON events USING GIN(tags);
CREATE INDEX idx_events_type ON events(type);
```

**Key Design Decisions:**
- **`transaction_id`**: Uses PostgreSQL's built-in `xid8` type for transaction IDs (generated by `pg_current_xact_id()`)
- **`position`**: `BIGSERIAL` auto-incrementing position within each transaction
- **`tags`**: PostgreSQL TEXT[] array for efficient querying and indexing
- **`data`**: JSON for flexible event payload storage
- **`occurred_at`**: Business timestamp (when the event logically occurred)
- **Type constraint**: Maximum 64 characters for event type names

### Commands Table

Audit trail for all commands executed:

```sql
CREATE TABLE commands (
    transaction_id xid8 NOT NULL PRIMARY KEY,
    type VARCHAR(64) NOT NULL,
    data JSONB NOT NULL,
    metadata JSONB,
    occurred_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP
);
```

**Purpose:**
- **Audit Trail**: Track all commands for debugging and compliance
- **Correlation**: Link commands to their generated events via `transaction_id`
- **Metadata**: Store additional information about command execution

### Transaction ID Generation

The system uses PostgreSQL's built-in transaction ID mechanism:

```sql
-- Transaction IDs are generated automatically using pg_current_xact_id()
SELECT pg_current_xact_id();
```

**Key Characteristics:**
- **Built-in PostgreSQL**: Uses `xid8` type for transaction IDs
- **Automatic Generation**: No custom sequences table needed
- **Transaction-scoped**: Each PostgreSQL transaction gets a unique ID
- **Monotonic**: Transaction IDs are guaranteed to be monotonically increasing

## SQL Functions

### Core Append Functions

#### 1. `append_events_batch()` - Unconditional Append

```sql
CREATE OR REPLACE FUNCTION append_events_batch(
    p_types TEXT[],
    p_tags TEXT[], -- array of Postgres array literals as strings
    p_data JSONB[]
) RETURNS VOID AS $$
BEGIN
    -- Insert directly into events table using UNNEST for better performance
    INSERT INTO events (type, tags, data, transaction_id)
    SELECT 
        t.type,
        t.tag_string::TEXT[], -- Cast the array literal string to TEXT[]
        t.data,
        pg_current_xact_id() -- Use PostgreSQL's built-in transaction ID
    FROM UNNEST($1, $2, $3) AS t(type, tag_string, data);
END;
$$ LANGUAGE plpgsql;
```

#### 2. `append_events_with_condition()` - Conditional Append

```sql
CREATE OR REPLACE FUNCTION append_events_with_condition(
    p_types TEXT[],
    p_tags TEXT[], -- array of Postgres array literals as strings
    p_data JSONB[],
    p_condition JSONB DEFAULT NULL
) RETURNS JSONB AS $$
DECLARE
    fail_if_events_match JSONB;
    after_cursor JSONB;
    condition_result JSONB;
BEGIN
    -- Extract condition parameters
    IF p_condition IS NOT NULL THEN
        fail_if_events_match := p_condition->'fail_if_events_match';
        IF p_condition->'after_cursor' IS NOT NULL AND p_condition->'after_cursor' != 'null' THEN
            after_cursor := p_condition->'after_cursor';
        END IF;
    END IF;
    
    -- Check append conditions first
    condition_result := check_append_condition(fail_if_events_match, after_cursor);
    
    -- If conditions failed, return the failure status
    IF (condition_result->>'success')::boolean = false THEN
        RETURN condition_result;
    END IF;
    
    -- If conditions pass, insert events using UNNEST for all cases
    PERFORM append_events_batch(p_types, p_tags, p_data);
    
    -- Return success status
    RETURN jsonb_build_object(
        'success', true,
        'message', 'events appended successfully',
        'events_count', array_length(p_types, 1)
    );
END;
$$ LANGUAGE plpgsql;
```

#### 3. `append_events_with_advisory_locks()` - Advisory Lock Append

```sql
CREATE OR REPLACE FUNCTION append_events_with_advisory_locks(
    p_types TEXT[],
    p_tags TEXT[], -- array of Postgres array literals as strings for storage
    p_data JSONB[],
    p_lock_tags TEXT[], -- array of Postgres array literals as strings for advisory locks
    p_condition JSONB DEFAULT NULL,
    p_lock_timeout_ms INTEGER DEFAULT 5000 -- 5 second default timeout
) RETURNS JSONB AS $$
DECLARE
    fail_if_events_match JSONB;
    after_cursor JSONB;
    lock_keys TEXT[];
    tag_array TEXT[];
    lock_key TEXT;
    i INTEGER;
    lock_timeout_setting TEXT;
    condition_result JSONB;
BEGIN
    -- Set lock timeout for this transaction
    lock_timeout_setting := current_setting('lock_timeout', true);
    PERFORM set_config('lock_timeout', p_lock_timeout_ms::TEXT, false);
    
    -- Extract condition parameters
    IF p_condition IS NOT NULL THEN
        fail_if_events_match := p_condition->'fail_if_events_match';
        IF p_condition->'after_cursor' IS NOT NULL AND p_condition->'after_cursor' != 'null' THEN
            after_cursor := p_condition->'after_cursor';
        END IF;
    END IF;
    
    -- Process each event's lock tags to acquire advisory locks
    FOR i IN 1..array_length(p_lock_tags, 1) LOOP
        -- Parse the lock tags array string into actual array
        tag_array := p_lock_tags[i]::TEXT[];
        
        -- Acquire advisory locks for all lock keys (sorted to prevent deadlocks)
        IF array_length(tag_array, 1) > 0 THEN
            FOR lock_key IN SELECT unnest(tag_array ORDER BY tag_array) LOOP
                PERFORM pg_advisory_xact_lock(hashtext(lock_key));
            END LOOP;
        END IF;
    END LOOP;
    
    -- Check append conditions
    condition_result := check_append_condition(fail_if_events_match, after_cursor);
    
    -- If conditions failed, return the failure status
    IF (condition_result->>'success')::boolean = false THEN
        RETURN condition_result;
    END IF;
    
    -- If conditions pass, insert events using UNNEST for all cases
    PERFORM append_events_batch(p_types, p_tags, p_data);
    
    -- Return success status
    RETURN jsonb_build_object(
        'success', true,
        'message', 'events appended successfully with advisory locks',
        'events_count', array_length(p_types, 1)
    );
END;
$$ LANGUAGE plpgsql;
```

### Query Functions

#### `query_events()` - Event Querying

```sql
CREATE OR REPLACE FUNCTION query_events(
    query_type TEXT DEFAULT NULL,
    query_tags TEXT[] DEFAULT NULL,
    query_data JSONB DEFAULT NULL,
    cursor_transaction_id BIGINT DEFAULT NULL,
    cursor_position INTEGER DEFAULT NULL,
    limit_count INTEGER DEFAULT 100
) RETURNS TABLE(
    id BIGINT,
    type TEXT,
    tags TEXT[],
    data JSONB,
    transaction_id BIGINT,
    position INTEGER,
    occurred_at TIMESTAMP WITH TIME ZONE
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        e.id,
        e.type,
        e.tags,
        e.data,
        e.transaction_id,
        e.position,
        e.occurred_at
    FROM events e
    WHERE (query_type IS NULL OR e.type = query_type)
        AND (query_tags IS NULL OR e.tags @> query_tags)
        AND (query_data IS NULL OR e.data @> query_data)
        AND (
            cursor_transaction_id IS NULL 
            OR e.transaction_id > cursor_transaction_id
            OR (e.transaction_id = cursor_transaction_id AND e.position > cursor_position)
        )
    ORDER BY e.transaction_id ASC, e.position ASC
    LIMIT limit_count;
END;
$$ LANGUAGE plpgsql;
```

### Projection Functions

#### `project_state()` - State Projection

```sql
CREATE OR REPLACE FUNCTION project_state(
    projector_configs JSONB,
    cursor_transaction_id BIGINT DEFAULT NULL,
    cursor_position INTEGER DEFAULT NULL
) RETURNS JSONB AS $$
DECLARE
    projector_config JSONB;
    projector_type TEXT;
    projector_tags TEXT[];
    projector_data JSONB;
    projector_result JSONB;
    final_result JSONB := '{}'::JSONB;
BEGIN
    -- Process each projector configuration
    FOR projector_config IN SELECT * FROM jsonb_array_elements(projector_configs) LOOP
        projector_type := projector_config->>'type';
        projector_tags := ARRAY(SELECT jsonb_array_elements_text(projector_config->'tags'));
        projector_data := projector_config->'data';
        
        -- Apply projector logic based on type
        CASE projector_type
            WHEN 'count' THEN
                projector_result := project_count(projector_tags, projector_data, cursor_transaction_id, cursor_position);
            WHEN 'sum' THEN
                projector_result := project_sum(projector_tags, projector_data, cursor_transaction_id, cursor_position);
            WHEN 'custom' THEN
                projector_result := project_custom(projector_tags, projector_data, cursor_transaction_id, cursor_position);
            ELSE
                RAISE EXCEPTION 'Unknown projector type: %', projector_type;
        END CASE;
        
        -- Merge result into final result
        final_result := final_result || projector_result;
    END LOOP;
    
    RETURN final_result;
END;
$$ LANGUAGE plpgsql;
```

## Advisory Locks Implementation

### Lock Key Generation

Lock keys are generated from event tags with the `lock:` prefix:

```go
// In Go code
for _, tag := range event.GetTags() {
    if strings.HasPrefix(tag.GetKey(), "lock:") {
        lockKey := strings.TrimPrefix(tag.GetKey(), "lock:")
        lockKeys = append(lockKeys, lockKey)
    }
}
```

### Lock Acquisition Strategy

```sql
-- In SQL function
FOR lock_key IN SELECT unnest(lock_tags[i]::TEXT[]) LOOP
    PERFORM pg_advisory_xact_lock(hashtext(lock_key));
END LOOP;
```

**Key Characteristics:**
- **Transaction-scoped**: Locks are automatically released when transaction commits/rolls back
- **Hash-based**: Uses `hashtext()` for consistent lock key generation
- **Ordered**: Locks are acquired in a consistent order to prevent deadlocks
- **Timeout-protected**: Uses `lock_timeout` setting to prevent indefinite waiting

### Lock Key Examples

```go
// Example lock keys
"course:CS101"           // Lock specific course
"student:student123"     // Lock specific student
"enrollment:CS101"       // Lock enrollment operations for course
"account:account456"     // Lock specific account
```

## Transaction Management

### Isolation Levels

The system supports three isolation levels:

```go
type IsolationLevel int

const (
    IsolationLevelReadCommitted IsolationLevel = iota
    IsolationLevelRepeatableRead
    IsolationLevelSerializable
)
```

**Default**: `ReadCommitted` for most operations

### Transaction Flow

1. **Begin Transaction**: Start with specified isolation level
2. **Acquire Locks**: If advisory locks are needed
3. **Validate Conditions**: Check append conditions
4. **Generate Transaction ID**: Update sequences table
5. **Insert Events**: Batch insert all events
6. **Insert Command**: Store command for audit trail
7. **Commit**: All changes become visible

### Timeout Management

```go
func (es *eventStore) withTimeout(ctx context.Context, defaultTimeoutMs int) (context.Context, context.CancelFunc) {
    if deadline, ok := ctx.Deadline(); ok {
        // Use caller's timeout
        return context.WithDeadline(context.Background(), deadline)
    }
    // Use default timeout
    return context.WithTimeout(context.Background(), time.Duration(defaultTimeoutMs)*time.Millisecond)
}
```

## Error Handling

### Custom Error Codes

```sql
-- Custom error codes for specific scenarios
DCB01: Append condition violated
DCB02: Lock acquisition timeout
DCB03: Invalid event data
```

### Error Types in Go

```go
type EventStoreError struct {
    Op  string
    Err error
}

type ValidationError struct {
    EventStoreError
    Field string
    Value string
}

type ConcurrencyError struct {
    EventStoreError
}

type ResourceError struct {
    EventStoreError
    Resource string
}
```

### Error Recovery

- **Validation Errors**: Fail fast, no database changes
- **Concurrency Errors**: Retry with exponential backoff
- **Resource Errors**: Check database connectivity and configuration
- **Lock Timeouts**: Increase timeout or reduce concurrency

## Performance Considerations

### Indexing Strategy

```sql
-- Primary query patterns
CREATE INDEX idx_events_type ON events(type);
CREATE INDEX idx_events_transaction_id ON events(transaction_id);
CREATE INDEX idx_events_occurred_at ON events(occurred_at);

-- Tag-based queries
CREATE INDEX idx_events_tags_gin ON events USING GIN(tags);

-- JSON data queries
CREATE INDEX idx_events_data_gin ON events USING GIN(data);

-- Cursor-based pagination
CREATE UNIQUE INDEX idx_events_transaction_position ON events(transaction_id, position);
```

### Batch Operations

- **Batch Size Limit**: Configurable via `MaxBatchSize` (default: 1000)
- **Array Parameters**: Use PostgreSQL arrays for efficient batch inserts
- **Transaction Scope**: All events in a batch share the same transaction ID

### Lock Performance

- **Hash-based Keys**: Fast lock key generation and comparison
- **Transaction-scoped**: No manual lock cleanup required
- **Timeout Protection**: Prevents indefinite waiting
- **Ordered Acquisition**: Prevents deadlocks

### Query Optimization

- **Cursor-based Pagination**: Efficient for large datasets
- **Tag-based Filtering**: Uses GIN indexes for fast array operations
- **JSONB Queries**: Leverages PostgreSQL's JSONB indexing
- **Limit Clauses**: Prevents memory exhaustion

## Monitoring and Debugging

### Key Metrics

```sql
-- Event throughput
SELECT 
    DATE_TRUNC('hour', occurred_at) as hour,
    COUNT(*) as event_count,
    COUNT(DISTINCT transaction_id) as transaction_count
FROM events 
WHERE occurred_at >= NOW() - INTERVAL '24 hours'
GROUP BY hour
ORDER BY hour;

-- Lock contention
SELECT 
    locktype,
    database,
    relation,
    page,
    tuple,
    virtualxid,
    transactionid,
    classid,
    objid,
    objsubid,
    virtualtransaction,
    pid,
    mode,
    granted
FROM pg_locks 
WHERE locktype = 'advisory';

-- Transaction distribution
SELECT 
    COUNT(*) as event_count,
    COUNT(DISTINCT transaction_id) as transaction_count,
    AVG(events_per_transaction) as avg_events_per_tx
FROM (
    SELECT transaction_id, COUNT(*) as events_per_transaction
    FROM events 
    GROUP BY transaction_id
) tx_stats;
```

### Debug Queries

```sql
-- View recent events with full details
SELECT 
    e.*,
    c.type as command_type,
    c.data as command_data
FROM events e
LEFT JOIN commands c ON e.transaction_id = c.transaction_id
WHERE e.occurred_at >= NOW() - INTERVAL '1 hour'
ORDER BY e.transaction_id DESC, e.position DESC
LIMIT 100;

-- Check for duplicate transaction IDs (should never happen)
SELECT transaction_id, COUNT(*) as count
FROM events 
GROUP BY transaction_id 
HAVING COUNT(*) > 1;

-- Find events with specific tags
SELECT * FROM events 
WHERE tags @> ARRAY['course_id:CS101', 'student_id:student123']
ORDER BY occurred_at DESC;
```

This low-level documentation provides the foundation for understanding how go-crablet works internally, enabling developers to optimize, debug, and extend the system effectively. 
This low-level documentation provides the foundation for understanding how go-crablet works internally, enabling developers to optimize, debug, and extend the system effectively. 